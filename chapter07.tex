\chapter{Prototype}
\section{Introduction}
This chapter discusses the prototype that provides a proof of concept for this research. Every module of the prototype discussed and described in this chapter. All architecture designs and specifications described in details. Note that not all modules and ideas that discussed here are implemented, this detail will be mentioned for every module.

This prototype presents an ability of programing using speech and represent code in a compact way. It is written in the Java language and uses different third party services and applications. Every service and application that used is discussed and described.

\section{Speech to Text}
This is a module which responsible for the translation from speech to text. The engine that is used for the STT process is Google Speech V2 server. It is shown in \citet{google15} how to interact with this server.
\subsection{Google Speech V2 Server}
Google Speech V2 server provides STT service with no charge for everyone who willing to use their service.
\remark{In order to use this service you have to be a chromium user (\url{https://www.chromium.org/}) because Google's server requires developer's key}.
\subsubsection{Host}
In order to access this service the host that need to be used is \url{https://www.google.com/speech-api/v2/recognize}.
\subsubsection{Request}
The request that is need to be sent to Google's server is:
\begin{lstlisting}
curl -X POST \
--data-binary @'test.flac' \
--header 'Content-Type: audio/x-flac; rate=44100;' \
'https://www.google.com/speech-api/v2/recognize?output=json&lang=en-us&key=AIzaSyDT41KV3j_c2OseWNNt4xv79MD9sj9p2j4'
\end{lstlisting}
Explanation about the curl:
\begin{description}
	\item [data-binary] is a path on your local machine to audio file that you want to translate.
	\item [header] is the information about encoding of the audio. In this example is flac with a bit rate of 44,100.
	\item [uri] is the host of the server with concatenation of the output format, language, and developer key. in this example we use json (output=json), english (lang=en-us), and our developer key is AIzaSyDT41KV3j\_c2OseWNNt4xv79MD9sj9p2j4.
\end{description}
\subsubsection{Response}
The response format is JSON. When Google is 100\% confident in it's translation, it will return the following object:
\begin{lstlisting}
	{
	   "result":
	   [
	   {
	   		"alternative":
	   		[
	   		{
	   			"transcript":"good morning Google how are you feeling today"
	   		}
	   		],
	   		"final":true
	   	}
	   	],
	   	"result_index":0
	}
\end{lstlisting}
When it's doubtful, it adds a confidence parameter for you. It also seems to add multiple transcripts for some reason.
\begin{lstlisting}
	{
		"result":
		[
		{
			"alternative":
			[
				{
					"transcript":"this is a test",
					"confidence":0.97321892
		        },
		        {
		        	"transcript":"this is a test for"
		        }
	      	],
	      	"final":true
	      }
	      ],
	      "result_index":0
	}
\end{lstlisting}
\subsection{Speech to Text Library}
This library used to bring speech recognition to Processing applications (processing is a programming language, development environment, and online community. Since 2001, Processing has promoted software literacy within the visual arts and visual literacy within technology). Using WebSocket, Google Chrome and Processing, you can get unlimited speech recognition results in your Sketch. As of May 2014, you need a developer API key to use this library. The new API has a limit of 50 requests/day.

This library is an open source with dependency in Processing, hence we had to make modifications so it will fit our needs. Several modifications have been made to this open source:
\begin{itemize}
	\item The dependency in Processing has been removed so the application could run as a simple Java project. 
	\item A new response parser has been developed because the one that was in use didn't know how to parse the new format of Google Speech V2.
	\item Auto Speech Recording had memory issues.
	\item Various redesign modifications.
\end{itemize}
It is shown in \citet{getflourish14} where to get the source code from and how to use it's API.
\section{BNF Parser} \label{section:BNF Parser}
\subsubsection{Antlr 4}
Antlr stands for Another Tool for Language Recognition. The tool is able to generate compiler or interpreter for any computer language. Besides obvious use, e.g. need to parse a real 'big' programming language such as Java, PHP or SQL, it can help with smaller, more common tasks.

It is useful any time you need to evaluate expressions unknown at compile-time or to parse non-trivial user input or files in a weird format. Of course, it is possible to create custom hand made parser for any of these tasks. However, it usually takes much more time and effort. A little knowledge of a good parser generator may turn these time-consuming tasks into easy and fast exercises.

ANTLR seems to be popular in open source word. Among others, it is used by Apache Camel, Apache Lucene, Apache Hadoop, Groovy and Hibernate. They all needed parser for a custom language. For example, Hibernate uses ANTLR to parse its query language HQL.

ANTLR is code generator. It takes so called grammar file as input and generates two classes: lexer and parser.

Lexer runs first and splits input into pieces called tokens. Each token represents more or less meaningful piece of input. The stream of tokes is passed to parser which do all necessary work. It is the parser who builds abstract syntax tree, interprets the code or translate it into some other form.

Grammar file contains everything ANTLR needs to generate correct lexer and parser. Whether it should generate java or python classes, whether parser generates abstract syntax tree, assembler code or directly interprets code and so on. As this tutorial shows how to build abstract syntax tree, we will ignore other options in following explanations.

Most importantly, grammar file describes how to split input into tokens and how to build tree from tokens. In other words, grammar file contains lexer rules and parser rules.

Each lexer rule describes one token: TokenName: regular expression; Parser rules are more complicated. The most basic version is similar as in lexer rule: ParserRuleName: regular expression;  

They may contain modifiers that specify special transformations on input, root and childs in result abstract syntax tree or actions to be performed whenever rule is used. Almost all work is usually done inside parser rules.