\chapter{Prototype}
\section{Introduction}
This chapter discusses the prototype that provides a proof of concept for this research. Every module of the prototype discussed and described in this chapter. All architecture designs and specifications described in details. Note that not all modules and ideas that discussed here are implemented, this detail will be mentioned for every module.

This prototype presents an ability of programing using speech and represent code in a compact way. It is written in the Java language and uses different third party services and applications. Every service and application that used is discussed and described.

\section{Speech to Text}
This is a module which responsible for the translation from speech to text. The engine that is used for the STT process is Google Speech V2 server. It is shown in \citet{google15} how to interact with this server.
\subsection{Google Speech V2 Server}
Google Speech V2 server provides STT service with no charge for everyone who willing to use their service.
\remark{In order to use this service you have to be a chromium user (\url{https://www.chromium.org/}) because Google's server requires developer's key}.
\subsubsection{Host}
In order to access this service the host that need to be used is \url{https://www.google.com/speech-api/v2/recognize}.
\subsubsection{Request}
The request that is need to be sent to Google's server is:
\begin{lstlisting}
curl -X POST \
--data-binary @'test.flac' \
--header 'Content-Type: audio/x-flac; rate=44100;' \
'https://www.google.com/speech-api/v2/recognize?output=json&lang=en-us&key=AIzaSyDT41KV3j_c2OseWNNt4xv79MD9sj9p2j4'
\end{lstlisting}
Explanation about the curl:
\begin{description}
	\item [data-binary] is a path on your local machine to audio file that you want to translate.
	\item [header] is the information about encoding of the audio. In this example is flac with a bit rate of 44,100.
	\item [uri] is the host of the server with concatenation of the output format, language, and developer key. in this example we use json (output=json), english (lang=en-us), and our developer key is AIzaSyDT41KV3j\_c2OseWNNt4xv79MD9sj9p2j4.
\end{description}
\subsubsection{Response}
The response format is JSON. When Google is 100\% confident in it's translation, it will return the following object:
\begin{lstlisting}
	{
	   "result":
	   [
	   {
	   		"alternative":
	   		[
	   		{
	   			"transcript":"good morning Google how are you feeling today"
	   		}
	   		],
	   		"final":true
	   	}
	   	],
	   	"result_index":0
	}
\end{lstlisting}
When it's doubtful, it adds a confidence parameter for you. It also seems to add multiple transcripts for some reason.
\begin{lstlisting}
	{
		"result":
		[
		{
			"alternative":
			[
				{
					"transcript":"this is a test",
					"confidence":0.97321892
		        },
		        {
		        	"transcript":"this is a test for"
		        }
	      	],
	      	"final":true
	      }
	      ],
	      "result_index":0
	}
\end{lstlisting}
\subsection{Speech to Text Library}
This library used to bring speech recognition to Processing applications (processing is a programming language, development environment, and online community. Since 2001, Processing has promoted software literacy within the visual arts and visual literacy within technology). Using WebSocket, Google Chrome and Processing, you can get unlimited speech recognition results in your Sketch. As of May 2014, you need a developer API key to use this library. The new API has a limit of 50 requests/day.

This library is an open source with dependency in Processing, hence we had to make modifications so it will fit our needs. Several modifications have been made to this open source:
\begin{itemize}
	\item The dependency in Processing has been removed so the application could run as a simple Java project. 
	\item A new response parser has been developed because the one that was in use didn't know how to parse the new format of Google Speech V2.
	\item Auto Speech Recording had memory issues.
	\item Various redesign modifications.
\end{itemize}
It is shown in \citet{getflourish14} where to get the source code from and how to use it's API.
\subsection{Testing the module}
In order to be sure that we may use this module in our system we performed several tests with several testers. We used the Linked List program that is presented in \autoref{fig63} to perform the main test. The following list is the result of the dictation of the Linked List program. Every command was dictated separately, each row is the result of the command.
\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|}
\hline
{\bf Expected Result} & {\bf Actual Result}                             & {\bf Match Score (\%)} \\ \hline
                      & create class linked list                        &                        \\ \hline
                      & create inner class node                         &                        \\ \hline
                      & create field data type object                   &                        \\ \hline
                      & make it public                                  &                        \\ \hline
                      & create public field next of type of object      &                        \\ \hline
                      & we are done with class node                     &                        \\ \hline
                      & create field tail of type node                  &                        \\ \hline
                      & create an int field size                        &                        \\ \hline
                      & create method iterator                          &                        \\ \hline
                      & return new ll interrater                        &                        \\ \hline
                      & number 2                                        &                        \\ \hline
                      & exit method                                     &                        \\ \hline
                      & create inner class LLL interrater               &                        \\ \hline
                      & create a constructor                            &                        \\ \hline
                      & assign head to field next node                  &                        \\ \hline
                      & assign false to field remove ok                 &                        \\ \hline
                      & assign minus 12 field post to remove            &                        \\ \hline
                      & number 2                                        &                        \\ \hline
                      & finish constructor                              &                        \\ \hline
                      & create method hasnext                           &                        \\ \hline
                      & return next node is not equal to null           &                        \\ \hline
                      & we are done with class LLL interrater           &                        \\ \hline
                      & create method get that accepts pose of type int &                        \\ \hline
                      & assert pose is between 0 and size               &                        \\ \hline
                      & ethos equals size -1                            &                        \\ \hline
                      & then assign tail. Data to result                &                        \\ \hline
                      & otherwise                                       &                        \\ \hline
                      & temp is a signed head                           &                        \\ \hline
                      & create a loop from one to pose                  &                        \\ \hline
                      & sign them. Next to temp                         &                        \\ \hline
                      & set result to temp. Data                        &                        \\ \hline
                      & return result                                   &                        \\ \hline
                      &                                                 &                        \\ \hline
\end{tabular}
\caption{My caption}
\label{table7}
\end{table}
\begin{itemize}
	\item create class linked list
	\item create inner class node
	\item create field data type object
	\item make it public
	\item create public field next of type of object
	\item we are done with class node
	\item create field tail of type node
	\item create an int field size
	\item create method iterator
	\item return new ll interrater
	\item number 2
	\item exit method
	\item create inner class LLL interrater
	\item create a constructor
	\item assign head to field next node
	\item assign false to field remove ok
	\item assign minus 12 field post to remove
	\item number 2
	\item finish constructor
	\item create method hasnext (I was shocked here!)
	\item return next node is not equal to null
	\item we are done with class LLL interrater
	\item create method get that accepts pose of type int
	\item assert pose is between 0 and size
	\item ethos equals size -1 (if pose equals size -1)
	\item then assign tail. Data to result
	\item otherwise
	\item temp is a signed head
	\item create a loop from one to pose
	\item sign them. Next to temp (assign temp. Next to temp)
	\item set result to temp. Data
	\item return result
\end{itemize}
 
\section{BNF Parser} \label{section:BNF Parser}
\subsubsection{Antlr 4}
Antlr stands for Another Tool for Language Recognition. The tool is able to generate compiler or interpreter for any computer language. Besides obvious use, e.g. need to parse a real 'big' programming language such as Java, PHP or SQL, it can help with smaller, more common tasks.

It is useful any time you need to evaluate expressions unknown at compile-time or to parse non-trivial user input or files in a weird format. Of course, it is possible to create custom hand made parser for any of these tasks. However, it usually takes much more time and effort. A little knowledge of a good parser generator may turn these time-consuming tasks into easy and fast exercises.

ANTLR seems to be popular in open source word. Among others, it is used by Apache Camel, Apache Lucene, Apache Hadoop, Groovy and Hibernate. They all needed parser for a custom language. For example, Hibernate uses ANTLR to parse its query language HQL.

ANTLR is code generator. It takes so called grammar file as input and generates two classes: lexer and parser.

Lexer runs first and splits input into pieces called tokens. Each token represents more or less meaningful piece of input. The stream of tokes is passed to parser which do all necessary work. It is the parser who builds abstract syntax tree, interprets the code or translate it into some other form.

Grammar file contains everything ANTLR needs to generate correct lexer and parser. Whether it should generate java or python classes, whether parser generates abstract syntax tree, assembler code or directly interprets code and so on. As this tutorial shows how to build abstract syntax tree, we will ignore other options in following explanations.

Most importantly, grammar file describes how to split input into tokens and how to build tree from tokens. In other words, grammar file contains lexer rules and parser rules.

Each lexer rule describes one token: TokenName: regular expression; Parser rules are more complicated. The most basic version is similar as in lexer rule: ParserRuleName: regular expression;  

They may contain modifiers that specify special transformations on input, root and childs in result abstract syntax tree or actions to be performed whenever rule is used. Almost all work is usually done inside parser rules.